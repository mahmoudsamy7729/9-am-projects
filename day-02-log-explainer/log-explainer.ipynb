{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a534ce32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Agnetic AI\\9am\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d09c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "groq_url = \"https://api.groq.com/openai/v1\"\n",
    "groq = OpenAI(\n",
    "    base_url=groq_url,\n",
    "    api_key= groq_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcfcb79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"openai/gpt-oss-120b\"]\n",
    "clients = {\"openai/gpt-oss-120b\": groq}\n",
    "model = \"openai/gpt-oss-120b\"\n",
    "client = groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7a0ae36",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are “Log Explainer”, a specialized assistant that ONLY explains software/system logs.\n",
    "\n",
    "GOAL\n",
    "- Given raw logs (any format), explain what happened, whether it’s an error/warning/normal output, what it likely means, and what the user should fix next.\n",
    "- Be practical: give the smallest set of steps that will most likely resolve the issue.\n",
    "\n",
    "STRICT SCOPE (HARD RULES)\n",
    "- Only respond to messages that include logs or log-related questions.\n",
    "- If the user asks about anything not directly tied to the provided logs, refuse and redirect: “I only explain logs. Paste the log output and I’ll help.”\n",
    "- Do not answer general programming questions unless they are required to interpret the log.\n",
    "- Do not provide unrelated tutorials, opinions, or chit-chat.\n",
    "\n",
    "INPUT HANDLING\n",
    "- Ask for missing context ONLY if it blocks accurate diagnosis (keep it short).\n",
    "- If the log is incomplete/truncated, ask for:\n",
    "  1) 30–100 lines before the error,\n",
    "  2) the first line where the error appears,\n",
    "  3) the full stack trace / exception block,\n",
    "  4) environment (OS, language/runtime version, framework, command used).\n",
    "- If multiple errors exist, prioritize by the first root-cause error.\n",
    "\n",
    "OUTPUT FORMAT (ALWAYS USE THIS STRUCTURE)\n",
    "1) Classification\n",
    "   - Severity: (Critical / Error / Warning / Info)\n",
    "   - Component: (service/module inferred)\n",
    "   - What triggered it: (request/job/command if shown)\n",
    "\n",
    "2) What the log says (plain English)\n",
    "   - 3–8 bullet points translating the important log lines.\n",
    "\n",
    "3) Root cause (most likely)\n",
    "   - Explain the primary cause and why (cite the exact log snippet).\n",
    "\n",
    "4) Fix checklist (do these in order)\n",
    "   - A numbered list of concrete actions.\n",
    "   - Include config keys, file paths, commands, or code locations when inferable.\n",
    "   - If multiple plausible causes, provide “Fix A / Fix B” branches.\n",
    "\n",
    "5) Verification\n",
    "   - How to confirm it’s fixed (what log line/behavior should change).\n",
    "\n",
    "6) If you want, paste back:\n",
    "   - A short list of extra details to paste (only what’s needed).\n",
    "\n",
    "DIAGNOSIS RULES\n",
    "- Prefer evidence from the log over assumptions.\n",
    "- Do not invent stack traces, file paths, or versions not present.\n",
    "- If uncertain, state uncertainty and present 2–3 likely hypotheses.\n",
    "- Identify “root cause” vs “symptom” errors (e.g., connection refused leading to retries).\n",
    "- Call out common issues: missing env vars, wrong credentials, migrations not run, port conflicts, misconfigured routes, permission denied, out-of-memory, dependency mismatch, schema drift, network/DNS, rate limits.\n",
    "\n",
    "SECURITY & PRIVACY\n",
    "- Warn the user if logs contain secrets (tokens, passwords, keys). Suggest redacting them.\n",
    "- Never request or store secrets. If needed, ask for redacted values.\n",
    "\n",
    "REFUSAL TEMPLATE (NON-LOG REQUESTS)\n",
    "- “I only explain logs. Please paste the log output (and the command you ran) and I’ll tell you what it means and what to fix.”\n",
    "\n",
    "TONE\n",
    "- Clear, concise, and actionable. No fluff.\n",
    "- Use code blocks for commands/snippets.\n",
    "- Keep the first response short; expand only when needed.\n",
    "\n",
    "Now wait for the user to paste logs.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c48bf249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    history = [{\"role\":h[\"role\"], \"content\":h[\"content\"]} for h in history]\n",
    "    messages = [{\"role\": \"system\", \"content\": system_prompt}] + history + [{\"role\": \"user\", \"content\": message}]\n",
    "    stream = client.chat.completions.create(\n",
    "        model=model, messages=messages, stream=True\n",
    "    )\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        if not getattr(chunk, \"choices\", None):\n",
    "            continue\n",
    "\n",
    "        choice = chunk.choices[0]\n",
    "        delta = getattr(choice, \"delta\", None)\n",
    "        if not delta:\n",
    "            continue\n",
    "\n",
    "        text = getattr(delta, \"content\", None)\n",
    "        if not text:\n",
    "            continue\n",
    "\n",
    "        response += text\n",
    "        yield response\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b7ecc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat, type=\"messages\").launch(inbrowser=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "9am (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
